{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMLAB pytorch study day1 (Training classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform은 [0,1] data를 [-1,1] range로 바꿔주는 과정입니다.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# train set 불러오기 \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# tensorflow와 다르게 placeholder 지정해주는 것이 아니라 (tensorflow도 물론 queue를 이용해 바로 학습할 수도 있지만)\n",
    "# DataLoader class를 호출하여 바로 dataset을 불러옵니다.\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\"\"\"\n",
    "    Data loader. Combines a dataset and a sampler, and provides\n",
    "    single- or multi-process iterators over the dataset.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): dataset from which to load the data.\n",
    "        batch_size (int, optional): how many samples per batch to load\n",
    "            (default: 1).\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "            at every epoch (default: False).\n",
    "        sampler (Sampler, optional): defines the strategy to draw samples from\n",
    "            the dataset. If specified, ``shuffle`` must be False.\n",
    "        batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
    "            indices at a time. Mutually exclusive with batch_size, shuffle,\n",
    "            sampler, and drop_last.\n",
    "        num_workers (int, optional): how many subprocesses to use for data\n",
    "            loading. 0 means that the data will be loaded in the main process\n",
    "            (default: 0)\n",
    "        collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
    "        pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
    "            into CUDA pinned memory before returning them.\n",
    "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
    "            if the dataset size is not divisible by the batch size. If False and\n",
    "            the size of dataset is not divisible by the batch size, then the last batch\n",
    "            will be smaller. (default: False)\n",
    "\"\"\"\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.view?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch는 필수적으로 사용하는 패키지들이 정해져 있습니다. torch.nn(nn), torch.autograd.Variable (Variable), torch.nn.functional (F)\n",
    "# 자주 사용하기 때문에 torch.nn torch.autograd.Variable 이렇게 매번 쓰기보다 직접 선언해놓는것이 편합니다.\n",
    "\n",
    "# autograd package에 Variable class를 import 해줍니다.\n",
    "# 흔히 텐서플로우의 tf.Variable 또는 tf.get_variable이라고 생각하시면 됩니다.\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# convolution, dense layer 등 layer class들이 포함되어 있습니다.\n",
    "# loss 계산에 필요한 loss class들도 nn package에 포함되어 있습니다.\n",
    "# nn.Module class를 보통 상속받아 원하는 네트워크 구조를 만듭니다.\n",
    "import torch.nn as nn\n",
    "\n",
    "# non linear 함수 등 다양한 함수를 포함하고있는 class 입니다.\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 network 구조를 만듭니다. nn.Module class를 상속받아 class를 새로 생성합니다. tensorflow에서 graph를 build 하는 것과 유사합니다.\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # 여기서 본인이 원하는 network 구조를 만들어줍니다.\n",
    "    # 간단한 convolutional network를 예시로 보여주고 있습니다. layer를 쌓는 형태로 선언해주면 됩니다. \n",
    "    # 단, 여기서(__init__)는 이어주지 않고 사용할 layer를 선언만 해줍니다. 실제로 계산은 forward 함수에 선언합니다.\n",
    "    def __init__(self):\n",
    "        \n",
    "        # 부모 class의 constructor를 불러옵니다.\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Conv2d의 parameter들은 차례로 [input_channel, output_channel, kernel_size] 입니다.\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        # Maxpool의 parameter들은 [kernel_size, stride] 입니다.\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        # pool에서 나온 channel갯수가 6일것이므로 input channel에 6을 넣는식입니다.\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 마지막 class 갯수만큼 확률값을 내뱉도록 network구조를 완성합니다.\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    \n",
    "    # __init__에서 선언한 layer들을 이어줄 차례입니다.\n",
    "    # nn.Module의 forward함수를 override하는것이기때문에 무조건 forward 함수로 선언합니다.\n",
    "    def forward(self, x):\n",
    "        # input으로 data batch x를 받습니다.\n",
    "        # tensorflow와 유사하게 쭉 따라가면서 layer를 쌓으면 됩니다.\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Tensor.view는 tensorflow의 reshape 함수와 동일합니다.\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # logit을 return 해줍니다.\n",
    "        return x\n",
    "\n",
    "    \n",
    "# network 구조가 다 완성되면 instance를 생성합니다.\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow의 tf.train.000optimizer 처럼 optimizer들이 들어있는 package입니다.\n",
    "import torch.optim as optim\n",
    "\n",
    "# nn package에서 classification을 위한 Cross-Entropy loss를 가져옵니다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer를 선언합니다.\n",
    "# 위에서 만든 network 구조에 있는 parameter 전부를 optimizer에 parameter로 넣어줍니다.\n",
    "# momentum은 http://aikorea.org/cs231n/neural-networks-3/#sgd 참고\n",
    "# weight decay도 parameter로 바로 넣어줄 수 있습니다.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 1.8591\n",
      "[1, 4000] loss: 1.7950\n",
      "[1, 6000] loss: 1.7734\n",
      "[1, 8000] loss: 1.7807\n",
      "[1, 10000] loss: 1.7546\n",
      "[1, 12000] loss: 1.7433\n",
      "[2, 2000] loss: 1.7322\n",
      "[2, 4000] loss: 1.7144\n",
      "[2, 6000] loss: 1.6955\n",
      "[2, 8000] loss: 1.6786\n",
      "[2, 10000] loss: 1.7093\n",
      "[2, 12000] loss: 1.6862\n",
      "[3, 2000] loss: 1.6621\n",
      "[3, 4000] loss: 1.6541\n",
      "[3, 6000] loss: 1.6496\n",
      "[3, 8000] loss: 1.6608\n",
      "[3, 10000] loss: 1.6346\n",
      "[3, 12000] loss: 1.6364\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    \n",
    "    # 2000 step마다의 loss 평균을 찍어주기 위해 running_loss를 선언합니다. tensorflow reduce_mean 함수 같은건 없습니다.\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # 위에서 선언한 trainloader를 iteration 합니다.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # batch만큼의 data를 가져옵니다.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Variable로 감싸줍니다.\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # gradient를 매 batch step마다 0으로 초기화시켜주는 작업입니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # batch data를 network에 넣어 forward 해줍니다.\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # batch loss 계산합니다.\n",
    "        # logit을 바로 넣어줍니다. softmax function은 아마도 criterion에서 알아서 계산해주는듯합니다.\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backpropagation을 위한 과정입니다.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        # network를 지나는 variable들 안에있는 값을 들고오려면 .data를 해야합니다.\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:\n",
    "            print \"[%d, %d] loss: %.4f\" % (epoch+1, i+1, running_loss/2000)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print \"Training Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GroundTruth: ', '  cat  ship  ship plane')\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Ground Truth를 뽑습니다.\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0129 -1.4325  0.2734  1.6490  0.2815  0.7594  1.6694 -0.3623 -0.8485 -0.6891\n",
       " 2.8998  1.9432 -0.0190 -1.2469 -0.4915 -2.3794 -2.7576 -1.3390  3.0353  1.6208\n",
       " 2.4572  1.9511 -0.4096 -1.7739 -0.6269 -2.7192 -2.1823 -1.4018  3.2863  2.3461\n",
       " 2.4308  2.0453 -0.1739 -1.0787 -0.6585 -1.9802 -2.3457 -1.4036  2.6141  1.5711\n",
       "[torch.FloatTensor of size 4x10]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max value와 argmax를 동시에 뱉어줍니다. axis=1로 max한 값입니다.\n",
    "_, predictions = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 38 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0,1] 마스킹 list가 나옵니다. 맞으면 1, 틀리면 0입니다.\n",
    "(predictions == labels).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떻게 하는지 잘 모르겠습니다. cuda가 없어서 에러가 났을수도.\n",
    "# net.cuda()\n",
    "# inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Questions\n",
    "\n",
    "model save?\n",
    "network instance가 메모리에 올라가있으면 continual learning 가능한지?\n",
    "network parameter 일부만 update하고 싶다면? scope의 개념\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
